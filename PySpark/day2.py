# ğ–ğğšğ­ğ¡ğğ« ğ“ğ²ğ©ğ ğˆğ§ ğ„ğšğœğ¡ ğ‚ğ¨ğ®ğ§ğ­ğ«ğ² ğğ«ğ¨ğ›ğ¥ğğ¦
ğ–ğ«ğ¢ğ­ğ ğšğ§ ğğ²ğ¬ğ©ğšğ«ğ¤ ğœğ¨ğğ ğ­ğ¨ ğŸğ¢ğ§ğ ğ­ğ¡ğ ğ­ğ²ğ©ğ ğ¨ğŸ ğ°ğğšğ­ğ¡ğğ« ğ¢ğ§ ğğšğœğ¡ ğœğ¨ğ®ğ§ğ­ğ«ğ² ğŸğ¨ğ« ğğ¨ğ¯ğğ¦ğ›ğğ« 2019.
ğ“ğ¡ğ ğ­ğ²ğ©ğ ğ¨ğŸ ğ°ğğšğ­ğ¡ğğ« ğ¢ğ¬ ğ‚ğ¨ğ¥ğ ğ¢ğŸ ğ­ğ¡ğ ğšğ¯ğğ«ğšğ ğ ğ°ğğšğ­ğ¡ğğ«_ğ¬ğ­ğšğ­ğ ğ¢ğ¬ ğ¥ğğ¬ğ¬ ğ­ğ¡ğšğ§ ğ¨ğ« ğğªğ®ğšğ¥ 15,
ğ‡ğ¨ğ­ ğ¢ğŸ ğ­ğ¡ğ ğšğ¯ğğ«ğšğ ğ ğ°ğğšğ­ğ¡ğğ«_ğ¬ğ­ğšğ­ğ ğ¢ğ¬ ğ ğ«ğğšğ­ğğ« ğ­ğ¡ğšğ§ ğ¨ğ« ğğªğ®ğšğ¥ 25 ğšğ§ğ ğ–ğšğ«ğ¦ ğ¨ğ­ğ¡ğğ«ğ°ğ¢ğ¬ğ.
 
ğ‘ğğ­ğ®ğ«ğ§ ğ«ğğ¬ğ®ğ¥ğ­ ğ­ğšğ›ğ¥ğ ğ¢ğ§ ğšğ§ğ² ğ¨ğ«ğğğ«.

  ğ’ğœğ¡ğğ¦ğš ğ€ğ§ğ ğƒğšğ­ğš:
================
 # Define the schema for the Weather DataFrame
weather_schema = StructType([
 StructField("country_id", IntegerType(), True),
 StructField("weather_state", IntegerType(), True),
 StructField("day", StringType(), True)
])
 
# Weather data
weather_data = [
 (2, 15, "2019-11-01"),
 (2, 12, "2019-10-28"),
 (2, 12, "2019-10-27"),
 (3, -2, "2019-11-10"),
 (3, 0, "2019-11-11"),
 (3, 3, "2019-11-12"),
 (5, 16, "2019-11-07"),
 (5, 18, "2019-11-09"),
 (5, 21, "2019-11-23"),
 (7, 25, "2019-11-28"),
 (7, 22, "2019-12-01"),
 (7, 20, "2019-12-02"),
 (8, 25, "2019-11-05"),
 (8, 27, "2019-11-15"),
 (8, 31, "2019-11-25"),
 (9, 7, "2019-10-23"),
 (9, 3, "2019-12-23")
]
# Define the schema for the Countries DataFrame
countries_schema = StructType([
 StructField("country_id", IntegerType(), True),
 StructField("country_name", StringType(), True)
])
 
countries_data = [
 (2, "USA"),
 (3, "Australia"),
 (7, "Peru"),
 (5, "China"),
 (8, "Morocco"),
 (9, "Spain")
]

#  Source code:

  
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import *

spark =SparkSession.builder.appName('weatherdataAnalysis').getOrCreate()

weather_schema = StructType([
 StructField("country_id", IntegerType(), True),
 StructField("weather_state", IntegerType(), True),
 StructField("day", StringType(), True)
])
 
# Weather data
weather_data = [
 (2, 15, "2019-11-01"),
 (2, 12, "2019-10-28"),
 (2, 12, "2019-10-27"),
 (3, -2, "2019-11-10"),
 (3, 0, "2019-11-11"),
 (3, 3, "2019-11-12"),
 (5, 16, "2019-11-07"),
 (5, 18, "2019-11-09"),
 (5, 21, "2019-11-23"),
 (7, 25, "2019-11-28"),
 (7, 22, "2019-12-01"),
 (7, 20, "2019-12-02"),
 (8, 25, "2019-11-05"),
 (8, 27, "2019-11-15"),
 (8, 31, "2019-11-25"),
 (9, 7, "2019-10-23"),
 (9, 3, "2019-12-23")
]
# Define the schema for the Countries DataFrame
countries_schema = StructType([
 StructField("country_id", IntegerType(), True),
 StructField("country_name", StringType(), True)
])
 
countries_data = [
 (2, "USA"),
 (3, "Australia"),
 (7, "Peru"),
 (5, "China"),
 (8, "Morocco"),
 (9, "Spain")
]


weather_df = spark.createDataFrame(data=weather_data,schema=weather_schema)

countries_df = spark.createDataFrame(data=countries_data,schema=countries_schema)

#weather_df.show()
#countries_df.show()

weather_avg_df = weather_df.groupBy("country_id").agg(avg("weather_state").alias("weather_avg"))
weather_avg_df = weather_avg_df.withColumn("weather_type", when(weather_avg_df.weather_avg <=15 , "Cold")
                                        .when(weather_avg_df.weather_avg>=25 , "Hot")
                                        .otherwise("Warm"))
result_df = weather_avg_df.join(countries_df,weather_avg_df.country_id == countries_df.country_id,"left")
result_df.select("country_name","weather_type").show()
  
